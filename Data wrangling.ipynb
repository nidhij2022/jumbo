{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "# **Data Wrangling Lab**\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Estimated time needed: **45 to 60** minutes\n"}, {"metadata": {}, "cell_type": "markdown", "source": "In this assignment you will be performing data wrangling.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Objectives\n"}, {"metadata": {}, "cell_type": "markdown", "source": "In this lab you will perform the following:\n"}, {"metadata": {}, "cell_type": "markdown", "source": "*   Identify duplicate values in the dataset.\n\n*   Remove duplicate values from the dataset.\n\n*   Identify missing values in the dataset.\n\n*   Impute the missing values in the dataset.\n\n*   Normalize data in the dataset.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Hands on Lab\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Import pandas module.\n"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Load the dataset into a dataframe.\n"}, {"metadata": {}, "cell_type": "code", "source": "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Finding duplicates\n"}, {"metadata": {}, "cell_type": "markdown", "source": "In this section you will identify duplicate values in the dataset.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Find how many duplicate rows exist in the dataframe.\n"}, {"metadata": {}, "cell_type": "code", "source": "# to find duplicates take your dataframe and run duplicated method\nstored_duplicates = df.duplicated()\n\n# now you can sum this new data\nstored_duplicates.sum()\n\n", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "154"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Removing duplicates\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Remove the duplicate rows from the dataframe.\n"}, {"metadata": {}, "cell_type": "code", "source": "# this creates an objuect free of duplicates \ndf.drop_duplicates()\n\n\n# now I will create an object free of duplicates and save it\nduplicate_free = df.drop_duplicates()\n", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Verify if duplicates were actually dropped.\n"}, {"metadata": {}, "cell_type": "code", "source": "# or you can simply take the duplicates out of your dataframe with inplace\ndf.drop_duplicates(inplace=True)\n", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# now I will count how many duplicates are left to test\ndf.duplicated().sum()\n", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "0"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Finding Missing values\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Find the missing values for all columns.\n"}, {"metadata": {}, "cell_type": "code", "source": "# Pandas.isnull - This function takes a scalar or array-like object and indicates whether values are missing \n# (NaN in numeric arrays, None or NaN in object arrays, NaT in datetimelike)\n\n\n\n# now i will use the Isnull function to find nan and na values \n# then I will use the sum function to count the missing values\ndf.isnull().sum()\n", "execution_count": 8, "outputs": [{"output_type": "execute_result", "execution_count": 8, "data": {"text/plain": "Respondent        0\nMainBranch        0\nHobbyist          0\nOpenSourcer       0\nOpenSource       81\n               ... \nSexuality       542\nEthnicity       675\nDependents      140\nSurveyLength     19\nSurveyEase       14\nLength: 85, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Find out how many rows are missing in the column 'WorkLoc'\n"}, {"metadata": {}, "cell_type": "code", "source": "# now we will use the isnull with the sum function on a single column\n\n# this is how we can select a column - just use this syntax dataframe_name[\"column_name\"] \nselected_column = df[\"WorkLoc\"]\n\n\n# now we can use the isnull with the sum function to find out how many rows are missing\nselected_column.isnull().sum()\n", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "32"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Find out how many rows are missing in the column 'WorkLoc'\n\n# your code goes here\n\ndf['Country'].isna().sum()", "execution_count": 31, "outputs": [{"output_type": "execute_result", "execution_count": 31, "data": {"text/plain": "0"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Imputing missing values\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Find the  value counts for the column WorkLoc.\n"}, {"metadata": {}, "cell_type": "code", "source": "# now I will use the value count method\n# the value count method Returns a Series containing counts of unique values\n\nvalues_counts_workloc = df[\"WorkLoc\"].value_counts()\n\n# display \nvalues_counts_workloc\n", "execution_count": 11, "outputs": [{"output_type": "execute_result", "execution_count": 11, "data": {"text/plain": "Office                                            6806\nHome                                              3589\nOther place, such as a coworking space or cafe     971\nName: WorkLoc, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Identify the value that is most frequent (majority) in the WorkLoc column.\n"}, {"metadata": {}, "cell_type": "code", "source": "#make a note of the majority value here, for future reference\n# Now we can use the (index max) indxmax  method on our new object\n#to return the maximum (on the axis we want) \nvalues_counts_workloc.idxmax()", "execution_count": 12, "outputs": [{"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "'Office'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# now lets save that variable for later \ncommon_value = df[\"WorkLoc\"].value_counts().idxmax()\n\n# display\ncommon_value", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "'Office'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n"}, {"metadata": {}, "cell_type": "code", "source": "# To replace the NA and Nan Values we can use pandas fillna method\n# the fillna method fills Na and Nan's with a value\n\ndf[\"WorkLoc\"].fillna(value=common_value)\n# this will create an object that has the Na and Nan values replaced with the common value \"office\"\n", "execution_count": 14, "outputs": [{"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "0                                                  Home\n1                                                Office\n2                                                  Home\n3                                                  Home\n4        Other place, such as a coworking space or cafe\n                              ...                      \n11547                                              Home\n11548                                              Home\n11549                                            Office\n11550                                              Home\n11551                                            Office\nName: WorkLoc, Length: 11398, dtype: object"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "After imputation there should ideally not be any empty rows in the WorkLoc column.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Verify if imputing was successful.\n"}, {"metadata": {}, "cell_type": "code", "source": "# now lets make those changes to our dataframe with inplace\ndf[\"WorkLoc\"].fillna(value=common_value, inplace=True)\n\n", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# now we can check to make sure our changes worked\ndf[\"WorkLoc\"].isnull().sum()", "execution_count": 16, "outputs": [{"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "0"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Normalizing data\n"}, {"metadata": {}, "cell_type": "markdown", "source": "There are two columns in the dataset that talk about compensation.\n\nOne is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n\nThe other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\".\n\nThis makes it difficult to compare the total compensation of the developers.\n\nIn this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n\nOnce this column is ready, it makes comparison of salaries easy.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "List out the various categories in the column 'CompFreq'\n"}, {"metadata": {}, "cell_type": "code", "source": "# you can easily get the categories with the value count method\ndf[\"CompFreq\"].value_counts()\n\n", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "Yearly     6073\nMonthly    4788\nWeekly      331\nName: CompFreq, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Double click to see the **Hint**.\n\n<!--\n\nUse the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n\nIf the CompFreq is Yearly then use the exising value in CompTotal\nIf the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\nIf the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n\n-->\n"}, {"metadata": {}, "cell_type": "code", "source": "# lets start with a function that can handle our logic \n\ndef compensation_calc(frequency, compensation):\n    yearly_compensation = 0    \n\n    \n    # we can just keep the yearly as is\n    if frequency == \"Yearly\":        \n        yearly_compensation = compensation        \n        \n    # now we have to multiply by 12 for the month   \n    elif frequency == \"Monthly\":        \n        yearly_compensation = compensation * 12        \n        \n    # now we have to multiply by 52 for the weeks  \n    elif frequency == \"Weekly\":        \n        yearly_compensation = compensation * 52\n\n        \n    return yearly_compensation\n", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#The way I am going to do this is to make a list and add it to my dataframe\n# with the itterrows we can itterarte through our dataframe\n#(use head to save time)\nfor i, row in df.head(20).iterrows():\n    \n    #now lets move through each row and grab the values we need\n    period = row[\"CompFreq\"]\n    payment = row[\"CompTotal\"]\n    \n    \n    # lets test with a print\n    print (row[\"CompFreq\"], row[\"CompTotal\"])", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "Yearly 61000.0\nYearly 138000.0\nYearly 90000.0\nMonthly 29000.0\nYearly 90000.0\nMonthly 9500.0\nMonthly 3000.0\nYearly 103000.0\nYearly 69000.0\nMonthly 8000.0\nMonthly 7000.0\nYearly 114000.0\nWeekly 2000.0\nWeekly 22000.0\nMonthly 96000.0\nYearly 156000.0\nYearly 18000.0\nMonthly 6400.0\nMonthly 5000.0\nYearly 400000.0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# now I can test how these work together\nfor i, row in df.head(20).iterrows():\n    period = row[\"CompFreq\"]\n    payment = row[\"CompTotal\"]\n    \n    # we can run the caluclation on our data\n    calc_result = compensation_calc(frequency=period, compensation=payment)\n    \n    # with this we can check with a statement\n    print(f\"This person is earns {payment, period}. That means they make {calc_result} a year\")", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "This person is earns (61000.0, 'Yearly'). That means they make 61000.0 a year\nThis person is earns (138000.0, 'Yearly'). That means they make 138000.0 a year\nThis person is earns (90000.0, 'Yearly'). That means they make 90000.0 a year\nThis person is earns (29000.0, 'Monthly'). That means they make 348000.0 a year\nThis person is earns (90000.0, 'Yearly'). That means they make 90000.0 a year\nThis person is earns (9500.0, 'Monthly'). That means they make 114000.0 a year\nThis person is earns (3000.0, 'Monthly'). That means they make 36000.0 a year\nThis person is earns (103000.0, 'Yearly'). That means they make 103000.0 a year\nThis person is earns (69000.0, 'Yearly'). That means they make 69000.0 a year\nThis person is earns (8000.0, 'Monthly'). That means they make 96000.0 a year\nThis person is earns (7000.0, 'Monthly'). That means they make 84000.0 a year\nThis person is earns (114000.0, 'Yearly'). That means they make 114000.0 a year\nThis person is earns (2000.0, 'Weekly'). That means they make 104000.0 a year\nThis person is earns (22000.0, 'Weekly'). That means they make 1144000.0 a year\nThis person is earns (96000.0, 'Monthly'). That means they make 1152000.0 a year\nThis person is earns (156000.0, 'Yearly'). That means they make 156000.0 a year\nThis person is earns (18000.0, 'Yearly'). That means they make 18000.0 a year\nThis person is earns (6400.0, 'Monthly'). That means they make 76800.0 a year\nThis person is earns (5000.0, 'Monthly'). That means they make 60000.0 a year\nThis person is earns (400000.0, 'Yearly'). That means they make 400000.0 a year\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# now I'm going to add it to a list to add to my dataframe\n\n# first I will make a list\ntotal_comp = []\n\n#now I'm going to add my data to the list\nfor i, row in df.head(20).iterrows():\n    period = row[\"CompFreq\"]\n    payment = row[\"CompTotal\"]    \n    calc_result = compensation_calc(frequency=period, compensation=payment)\n    \n    total_comp.append(calc_result)\n    \nprint(total_comp)", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "[61000.0, 138000.0, 90000.0, 348000.0, 90000.0, 114000.0, 36000.0, 103000.0, 69000.0, 96000.0, 84000.0, 114000.0, 104000.0, 1144000.0, 1152000.0, 156000.0, 18000.0, 76800.0, 60000.0, 400000.0]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "total_comp = []\n\nfor i, row in df.iterrows():   \n    calc_result = compensation_calc(frequency=row[\"CompFreq\"], compensation=row[\"CompTotal\"])    \n    total_comp.append(calc_result)\n", "execution_count": 25, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# then I will check my list to see if it matches my dataframe    \nprint(len(total_comp))\ndf.shape", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "11398\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "(11398, 85)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#so to make a new column you can just use name_of_dataframe[name_of_column] = series`\n\ntotal_comp = []\n\nfor i, row in df.iterrows():   \n    calc_result = compensation_calc(frequency=row[\"CompFreq\"], compensation=row[\"CompTotal\"])    \n    total_comp.append(calc_result)\n    \ndf[\"NormalizedAnnualCompensation\"] = total_comp", "execution_count": 29, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.shape", "execution_count": 30, "outputs": [{"output_type": "execute_result", "execution_count": 30, "data": {"text/plain": "(11398, 86)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Authors\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Ramesh Sannareddy\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Other Contributors\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Rav Ahuja\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Change Log\n"}, {"metadata": {}, "cell_type": "markdown", "source": "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n| ----------------- | ------- | ----------------- | ---------------------------------- |\n| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Copyright \u00a9 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2022-01-01&cm_mmc=Email_Newsletter-\\_-Developer_Ed%2BTech-\\_-WW_WW-\\_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}